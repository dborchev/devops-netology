# Домашнее задание к занятию "5.1. Введение в виртуализацию. Типы и функции гипервизоров. Обзор рынка вендоров и областей применения."
https://github.com/netology-code/virt-homeworks/blob/virt-11/05-virt-01-basics/README.md

## Задача 1

> Опишите кратко, как вы поняли: в чем основное отличие полной (аппаратной) виртуализации, паравиртуализации и виртуализации на основе ОС.

Аппаратная виртуализация требует аппаратной поддержки, например отдельных инструкций в процессоре, отдельных таблиц страниц памяти (обычная такая таблица связывает страницу и процесс, а в виртуализации нужно связывать экземпляр виртуальной машины со страницей), отдельные прерывания, передающие управление гипервизору.
Соответственно, гипервизоры с поддержкой аппаратной виртуализации тесно работают с производителями процессоров для доступа к таким средствам.

Паравиртуализация идет в обратную сторону, и для достижения тех же целей требует встраивания кода в гостевые операционные системы. Таким кодом могут быть прямые изменения в ядре, или драйверы. Так, для форсирования освобождения памяти, требуется "надувной" (baloon) драйвер, который забирает неиспользуемую память из гостевой системы. 
Соответственно, паравиртуализация, в отличии от аппаратной, требует сотрудничества с разработчиком программного обеспечения, тогда как на аппаратной виртуализации сотрудничество не обязательно и в принципе возможно виртуализовать любую систему.

Виртуализация на основе ОС стоит в стороне от вышеназванных, поскольку описывает что управляет реальными аппаратными ресурсами, а не механизм виртуализации как таковой.
Виртуализация на основе операционной систем предполагает, что "полноценная" операционная система продолжает работу и управление аппаратными ресурсами. 
Как указано в лекции, виртуализации могла подлежать только система на основе такого же ядра, что и основная. Дочерние ядра естественным образом совместимы с родительским и совершают нужные вызовы напрямую.
Это также экономит память, поскольку достаточно присутствия одного экземпляра кода ядра для всех виртуализованных таким образом систем. Отдельно хранятся только структуры метаданных, такие как таблицы страниц и процессов. 


## Задача 2

> Выберите один из вариантов использования организации физических серверов, в зависимости от условий использования.
> Опишите, почему вы выбрали к каждому целевому использованию такую организацию.
> Организация серверов:
> - физические сервера,
> - паравиртуализация,
> - виртуализация уровня ОС.

Условия использования:
- Высоконагруженная база данных, чувствительная к отказу.
  - физические сервера
  - ближе к железу -- больше производительность (точнее, КПД); высоким нагрузкам нужно предоставлять лучшую возможную производительность
  - отказы в базах данных лучше решать средствами самих систем управления базами данных, которые умеют различные типы репликации, и (в отличии от какой-либо системы виртуализации) знают когда некоторая транзакция завершена корректно (== сами заботятся о целостности данных) 
- Различные web-приложения.
  - веб-приложения бывают разные, как и нагрузки на них:
    - например, для хостинга большого числа более-менее одинаковых систем, подойдет виртуализация уровня ОС
    - когда приложения и нагрузки разные, паравиртуализация дает больше гибкости для запуска разнородных систем
    - иногда софт "не очень" и не поддерживает горизонтальное масштабирование, тогда для высоких нагрузок на веб-приложение можно использовать и выделенные физические сервера
- Windows системы для использования бухгалтерским отделом.
  - паравиртуализация, поскольку у сотрудников бухгалтерского отдела разные функции, разные инструменты, и разные пики нагрузки по месяцам и сезонам. Виртуализации уровня ОС кажется привлекательной, пока мы не встречаемся с банк-клиентом, которые требует Windows XP, в то время как мы хотим обновлять всю инфраструктуру для закрытия багов. Тогда, возможность виртуализовать и изолировать разнородные системы становится полезной.
- Системы, выполняющие высокопроизводительные расчеты на GPU
  - физические сервера
  - ближе к железу -- больше производительность (точнее, КПД); высоким нагрузкам нужно предоставлять лучшую возможную производительность

## Задача 3

> Выберите подходящую систему управления виртуализацией для предложенного сценария. Детально опишите ваш выбор.

Сценарии:
1. 100 виртуальных машин на базе Linux и Windows, общие задачи, нет особых требований. Преимущественно Windows based инфраструктура, требуется реализация программных балансировщиков нагрузки, репликации данных и автоматизированного механизма создания резервных копий.
   1. одинаково хорошо будут работать VMware ESXi и Microsoft HyperV, как и облачные системы вроде Microsoft Azure или Amazon EC2
   2. раз у нас нет "особых требований", то подойдет все что угодно; почти наверняка в такой ситуации лучший выбор -- то с чем имеет наибольший опыт группа людей которая будет администрировать систему, а технические характеристики вторичны. Больший опыт работы влечет за собой большую надежность, что важнее для конечного пользователя, когда нет других требований.   
2. Требуется наиболее производительное бесплатное open source решение для виртуализации небольшой (20-30 серверов) инфраструктуры на базе Linux и Windows виртуальных машин.
   1. Qemu + Xen в качестве гипервизора с аппаратной поддержкой для максимальной производительности: оба продукта бесплатны и поставляются с открытым кодом, поддерживают Linux и Windows
3. Необходимо бесплатное, максимально совместимое и производительное решение для виртуализации Windows инфраструктуры.
   1. Microsoft Hyper-V почти наверняка будет давать наибольшую производительность и совместимость при виртуализации различных Windows систем, и также поддерживает Linux если такое требование появится в будущем. Продукт "бесплатен" в том смысле что поставляется с лицензией Windows Server начиная с уровня Standard
4. Необходимо рабочее окружение для тестирования программного продукта на нескольких дистрибутивах Linux.
   1. если тестирование не происходит непрерывно, а "по требованию" (новый релиз проходит по CI/CD пайплайну), то облачные системы вроде AWS EC2, Microsoft Azure, GCP Compute Engine становятся лучшим экономическим выбором, поскольку минимизируют простой ресурсов. Так, если тестирование запускается только "на ночь" и идет 8 часов, то остальные 16 часов в сутки такая инфраструктура не нужна.
   2. даже если тестирование непрерывно, то использование таких инфраструктур имеет экономический смысл, поскольку экономится время разработчиков за счет абстракции инфраструктуры (infrastructure as code) для построения тестовых сред (и их модификации в будущем) и других интерфейсов, перемещающих трудозатраты на сторону поставщика услуг

## Задача 4

> Опишите возможные проблемы и недостатки гетерогенной среды виртуализации (использования нескольких систем управления виртуализацией одновременно) и что необходимо сделать для минимизации этих рисков и проблем. Если бы у вас был выбор, то создавали бы вы гетерогенную среду или нет? Мотивируйте ваш ответ примерами.

Для начала, единственное преимущество гетерогенной среды -- независимость от одного поставщика (разработчика). Есть экономические факторы:
- снятие lock-in (зависимости от одного поставщика)
- появление экономического рычага при закупках у поставщиков
Прочие факторы:
- снижение уязвимости к дефектам и дырам безопасности одного поставщика
- снижение внутренних рисков (таких как "автобусный фактор") за счет распределения знаний

Основные проблемы также организационно-экономические:
- для управления сколь-либо сложной инфраструктурой нужен штат кратного размера (нужны эксперты по Hyper-V и еще эксперты по ESXi, и т.д.)
- нужен отдельный централизованный архитектурный отдел, который определяет направление для всех групп виртуализации сразу, определяет политику для поддерживающей их инфраструктуры (аппаратных серверов)
- культурная проблема: возможны "войны" между такими отделами

Далее, в такой организации мы сталкиваемся с небольшими техническими сложностями, поскольку такая организация вынуждена также разработать (или приобрести, или что-то посередине) единую систему управления ("оркестрации") различными системами виртуализации. Здесь оказывается, что
- функции которые в рекламных проспектах озвучены одинаково в реальности реализованы по-разному
- в отличии от например сетевых технологий, в системной виртуализации отсутствует меж-вендорная стандартизация, и любая граница взаимодействия между средами сложна и может измениться в следующей версии

Для минимизации этих рисков и проблем, организация которая хочет такое попробовать должна сначала научиться управлять двумя параллельными инфраструктурами одного типа. Например, две параллельных инсталляции ESXi, управляемых разными группами инженеров.
Общение между ними должно идти только через централизованную группу и периодические конференции для обмена опытом. После появления необходимых навыков управления и организационных структур, можно начинать техническое разделение двух групп, каждая из которых "идет своим путем".

> Если бы у вас был выбор, то создавали бы вы гетерогенную среду или нет?

Ответ зависит от потребностей бизнеса.

Если риски связанные с lock-in (зависимостью от одного поставщика) действительно велики, и бизнес готов инвестировать годы трудозатрат инженеров и менеджеров (рассматриваем долгосрочную перспективу), это может быть оправданной стратегией. Нужно просчитать план, и начать двигаться по пути минимального риска, например как я описал выше.

Если же мы хотим строить гетерогенную инфраструктуру потому что "это модно" и "Амазон так делает", то нет, в такой ситуации я бы не создавал ничего подобного.
Здесь важно, что в поддержке и разработке систем виртуализации разных типов на разных уровнях в Амазоне заняты сотни, если не десятки сотен людей. Амазон зарабатывает деньги, предоставляя сервисы на базе разным систем виртуализации -- для них такая инвестиция имеет смысл. Важно, что Амазон строит такую систему вот уже 15 лет.

